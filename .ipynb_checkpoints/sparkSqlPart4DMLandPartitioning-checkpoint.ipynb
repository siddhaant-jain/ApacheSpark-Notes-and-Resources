{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7160e72c-93f0-4350-8c49-8fab4366d52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "os.environ[\"HADOOP_HOME\"] = \"C:\\\\Users\\\\SkJain\\\\Downloads\\\\Compressed\\\\winutils-master\\\\hadoop-3.2.2\"\n",
    "sys.path.append('C:\\\\Users\\\\SkJain\\\\Downloads\\\\Compressed\\\\winutils-master\\\\hadoop-3.2.2\\\\bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e5aa65f-30a1-4743-bf0a-abd201535938",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config(\"spark.ui.port\", \"0\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName('SparkSql'). \\\n",
    "    master('local'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57fc4c91-559f-448e-93a2-61de498973bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeQuery(query):\n",
    "    return spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3a55ad9-2cdb-405d-b4cd-208e9ac5291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "see_databases = \"SHOW DATABASES\"\n",
    "createdb = \"CREATE DATABASE IF NOT EXISTS siddhantdb\"\n",
    "select_database = \"USE siddhantdb\"\n",
    "check_current_db = \"SELECT current_database()\"\n",
    "see_tables = \"SHOW TABLES\"\n",
    "drop_table = \"DROP TABLE IF EXISTS {}\"\n",
    "\n",
    "orders_table = \"orders\"\n",
    "orders_partitioned_table = \"orders_partitioned\"\n",
    "orders_data_path = './datasets/orders'\n",
    "\n",
    "create_order_table = \"\"\" CREATE TABLE IF NOT EXISTS orders (\n",
    "    order_id INT,\n",
    "    order_date STRING,\n",
    "    order_cust_id INT,\n",
    "    order_status STRING\n",
    "    ) ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\n",
    "    STORED AS TEXTFILE\n",
    "\"\"\"\n",
    "\n",
    "create_order_table_partitioned = \"\"\" CREATE TABLE IF NOT EXISTS orders_partitioned (\n",
    "    order_id INT,\n",
    "    order_date STRING,\n",
    "    order_cust_id INT,\n",
    "    order_status STRING\n",
    "    ) PARTITIONED BY (order_month STRING) \n",
    "    ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\n",
    "    STORED AS TEXTFILE\n",
    "\"\"\"\n",
    "\n",
    "load_data = \"LOAD DATA LOCAL INPATH '{}' INTO TABLE {}\"\n",
    "\n",
    "load_into_orders_patition = \"LOAD DATA LOCAL INPATH filepath/order_07_file INTO TABLE orders_partitioned PARTITION (order_month = '2013-07')\"\n",
    "insert_into_orders_patition = \"INSERT INTO TABLE orders_partitioned PARTITION(order_month = '2013-11') SELECT * FROM orders WHERE order_date LIKE '2013-11%'\"\n",
    "\n",
    "see_top_n_data = \"SELECT * FROM {} LIMIT {}\"\n",
    "records_count = \"SELECT COUNT(1) FROM {}\"\n",
    "remove_data = \"TRUNCATE TABLE {}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "723c1d1f-a55d-476d-aa31-18c16f441a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "| namespace|\n",
      "+----------+\n",
      "|   default|\n",
      "|    nysedb|\n",
      "|siddhantdb|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "executeQuery(see_databases).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3836dad-75bd-4da9-b21b-3b6d26ca43ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|current_database()|\n",
      "+------------------+\n",
      "|           default|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "executeQuery(check_current_db).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a7a9e95-ac8b-40bd-816c-d1abd3efba4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "executeQuery(createdb).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8760410-2e94-4553-ae4a-f6786cb43068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "executeQuery(select_database).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a91af13-fd9d-4471-af8a-3a1a10f4ac43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|current_database()|\n",
      "+------------------+\n",
      "|        siddhantdb|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "executeQuery(check_current_db).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76a8b06f-dfeb-4fd9-b842-33f05b378263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "executeQuery(see_tables).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49c589ee-d003-4b4d-b609-79ebbae933ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "executeQuery(drop_table.format(orders_table)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "061d1d09-b5e1-4bc3-b1d0-caec79a9cf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "executeQuery(create_order_table).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c49338be-7786-479c-b882-a8da88d1b52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----------+\n",
      "|  database|tableName|isTemporary|\n",
      "+----------+---------+-----------+\n",
      "|siddhantdb|   orders|      false|\n",
      "+----------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "executeQuery(see_tables).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56781a90-a2ce-4b45-acd9-c6f9843cbe44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "executeQuery(load_data.format(orders_data_path, orders_table)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "352dc896-3242-40b8-845a-993e8f54cb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-------------+---------------+\n",
      "|order_id|          order_date|order_cust_id|   order_status|\n",
      "+--------+--------------------+-------------+---------------+\n",
      "|       1|2013-07-25 00:00:...|        11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:...|          256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:...|        12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:...|         8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:...|        11318|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:...|         7130|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:...|         4530|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:...|         2911|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:...|         5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:...|         5648|PENDING_PAYMENT|\n",
      "+--------+--------------------+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "executeQuery(see_top_n_data.format(orders_table, '10')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c85a83ee-4b36-45bc-807e-6196142252aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   68883|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "executeQuery(records_count.format(orders_table)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213f0ef0-2459-494d-aee0-f2373d9b4889",
   "metadata": {},
   "source": [
    "## Partitioning\n",
    "\n",
    "- each partition is equal to a particular value of a given column\n",
    "- spark sql doesn't support range partitioning and bucketing. bucketing is supported in hive\n",
    "- once table is created, we can add static partitions and load data into them\n",
    "- spark metastore and hive both support dynamic partitioning as well, where partition will be created based on value of partition column\n",
    "- partitioned table can be both managed or external"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15d2833-77d4-4ebf-ad20-24ca57c1b1fa",
   "metadata": {},
   "source": [
    "## Load vs Insert\n",
    "- LOAD will copy files by dividing them into blocks\n",
    "- LOAD is fastest way of getting data into spark metastore but there's minimum validation at file level\n",
    "- not transformations or validations can be done at data level\n",
    "- if any transformations is required while getting data to spark metastore, we need to use INSERT command\n",
    "- Usage scenario of insert\n",
    "    - change delimiters of i/p file\n",
    "    - change file format\n",
    "    - load data into partitioned tables\n",
    "    - apply any other transformation at data level\n",
    "\n",
    "- if we load file of any other format (say text file) to a table which is stored as some other format (say parquet), the load command will run successfully without throwing any errors (since no validation)\n",
    "- in the table folder in hdfs, we can see that file actually got copied also\n",
    "- but when we run the select command then it will saying that a file is not in parquet format\n",
    "\n",
    "### Inserting data using a stage table (to resolve the above issue)\n",
    "- create a stage table(temp) with the file format same as data (textfile in this eg.)\n",
    "- get all the data to this stage table (using load command since same file format)\n",
    "- then put all the data from stage table to main table (using insert command)\n",
    "    > INSERT INTO order_items SELECT * FROM order_items_stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d633f6f4-409f-4ac7-b6d8-93afa2591a0c",
   "metadata": {},
   "source": [
    "## Create Partitioned tables\n",
    "- to check the query see value of this variable: create_order_table_partitioned\n",
    "- since input data has 4 column and final table will have 5 (order_month will also be included) we cannot directly use LOAD command\n",
    "- full example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b53cc13-0382-4ed8-b7ff-2d88ab6820ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "| namespace|\n",
      "+----------+\n",
      "|   default|\n",
      "|    nysedb|\n",
      "|siddhantdb|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "executeQuery(see_databases).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68e55e6b-b484-4559-8b2e-d773293f025e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|current_database()|\n",
      "+------------------+\n",
      "|        siddhantdb|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "executeQuery(check_current_db).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03760cd8-3427-4284-bab5-028fcdeb69e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----------+\n",
      "|  database|tableName|isTemporary|\n",
      "+----------+---------+-----------+\n",
      "|siddhantdb|   orders|      false|\n",
      "+----------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "executeQuery(see_tables).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "390f4f53-1a8f-4f61-b4fc-08bd220aec22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-------------+---------------+\n",
      "|order_id|          order_date|order_cust_id|   order_status|\n",
      "+--------+--------------------+-------------+---------------+\n",
      "|       1|2013-07-25 00:00:...|        11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:...|          256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:...|        12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:...|         8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:...|        11318|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:...|         7130|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:...|         4530|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:...|         2911|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:...|         5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:...|         5648|PENDING_PAYMENT|\n",
      "+--------+--------------------+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "executeQuery(see_top_n_data.format(orders_table, '10')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0f3b88c8-7f9a-450a-a04b-e803afe82d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "executeQuery(drop_table.format(orders_partitioned_table))\n",
    "executeQuery(see_tables).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2173e00c-1547-4646-b7f0-f45bbb6fa89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "executeQuery(create_order_table_partitioned).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89b4050d-6b6c-42c4-aa2c-0f6bc69b8e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------+\n",
      "|  database|         tableName|isTemporary|\n",
      "+----------+------------------+-----------+\n",
      "|siddhantdb|orders_partitioned|      false|\n",
      "+----------+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "executeQuery(see_tables).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6c56fbf-ce7d-4163-a08a-cd496468e964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                                                                                                        |comment|\n",
      "+----------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+-------+\n",
      "|order_id                    |int                                                                                                                                              |null   |\n",
      "|order_date                  |string                                                                                                                                           |null   |\n",
      "|order_cust_id               |int                                                                                                                                              |null   |\n",
      "|order_status                |string                                                                                                                                           |null   |\n",
      "|order_month                 |string                                                                                                                                           |null   |\n",
      "|# Partition Information     |                                                                                                                                                 |       |\n",
      "|# col_name                  |data_type                                                                                                                                        |comment|\n",
      "|order_month                 |string                                                                                                                                           |null   |\n",
      "|                            |                                                                                                                                                 |       |\n",
      "|# Detailed Table Information|                                                                                                                                                 |       |\n",
      "|Database                    |siddhantdb                                                                                                                                       |       |\n",
      "|Table                       |orders_partitioned                                                                                                                               |       |\n",
      "|Owner                       |SkJain                                                                                                                                           |       |\n",
      "|Created Time                |Thu Apr 14 12:10:26 IST 2022                                                                                                                     |       |\n",
      "|Last Access                 |UNKNOWN                                                                                                                                          |       |\n",
      "|Created By                  |Spark 3.1.2                                                                                                                                      |       |\n",
      "|Type                        |MANAGED                                                                                                                                          |       |\n",
      "|Provider                    |hive                                                                                                                                             |       |\n",
      "|Table Properties            |[transient_lastDdlTime=1649918426]                                                                                                               |       |\n",
      "|Location                    |file:/C:/Users/SkJain/Documents/BigDataStackWorkspace/SparkLearn/ApacheSpark-Notes-and-Resources/spark-warehouse/siddhantdb.db/orders_partitioned|       |\n",
      "|Serde Library               |org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                                                                                               |       |\n",
      "|InputFormat                 |org.apache.hadoop.mapred.TextInputFormat                                                                                                         |       |\n",
      "|OutputFormat                |org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat                                                                                       |       |\n",
      "|Storage Properties          |[serialization.format=,, field.delim=,]                                                                                                          |       |\n",
      "|Partition Provider          |Catalog                                                                                                                                          |       |\n",
      "+----------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "executeQuery(f\"DESCRIBE FORMATTED {orders_partitioned_table}\").show(200, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f44167-6611-4bd2-a5b4-d8b8f81aa4a6",
   "metadata": {},
   "source": [
    "### Adding partitons to tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e13e085e-a12f-4e28-ad9e-8bc976d31245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a static partition using alter table\n",
    "add_static_part = f\"ALTER TABLE {orders_partitioned_table} ADD PARTITION (order_month='2013-07')\"\n",
    "\n",
    "#if order_month was int and adding multiple partition in one quert\n",
    "add_static_part_int = f\"ALTER TABLE {orders_partitioned_table} ADD PARTITION (order_month=201307) PARTITION (order_month=201308) PARTITION (order_month=201309)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aee341b-0c27-4b16-8ef0-89025e350b96",
   "metadata": {},
   "source": [
    "### loading data into partitioned tables\n",
    "- format and delimited should match. We need to pre partition the file on partition logic if we want to use LOAD command\n",
    "- assuming we split order file into these 3 files for each month 07, 08, 09 using any custom logic, manually or python or any other way\n",
    "- now we can load this data into partitioN using query in 'load_into_orders_patition' variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964a369b-edf7-459b-9658-886e1dd351f4",
   "metadata": {},
   "source": [
    "## Inserting data into partitions\n",
    "- not always practical to directly LOAD data into tables\n",
    "- raw data would usually require some intial transformation before inserting to the table for which we use the stage table approach.\n",
    "- now we can load this data into partitioN using query in 'insert_into_orders_patition' variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0882d07-07c2-4310-9e69-ee56383986d6",
   "metadata": {},
   "source": [
    "## Dynamic Partitioning\n",
    "- we don't need to pre-create the partitions. They'll be automatically created when we run an Insert command in table with dynamic partition\n",
    "- we need to set property 'hive.exec.dynamic.partition' to true\n",
    "- and we need to set 'hive.exec.dynamic.partition.mode' to nonstrict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f867eff-d660-4d7c-9832-cced601a58d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|current_database()|\n",
      "+------------------+\n",
      "|        siddhantdb|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT current_database()\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "75570cfe-5a1e-4040-b467-876d492b6f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------+\n",
      "|  database|         tableName|isTemporary|\n",
      "+----------+------------------+-----------+\n",
      "|siddhantdb|orders_partitioned|      false|\n",
      "+----------+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "416d98ab-443f-4994-8476-ae424a416e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS orders_partitioned\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "44287b58-cf64-497d-98cc-c740170dfcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(create_order_table).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e3f11077-284b-43ea-92b7-f36ef952ed12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----------+\n",
      "|  database|tableName|isTemporary|\n",
      "+----------+---------+-----------+\n",
      "|siddhantdb|   orders|      false|\n",
      "+----------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a86f4cdc-c521-4ef2-bc48-7f57f3fd01de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(load_data.format(orders_data_path, orders_table)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e1c839bc-7fae-4e98-8387-2b34e17ff44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+-------------+---------------+\n",
      "|order_id|order_date           |order_cust_id|order_status   |\n",
      "+--------+---------------------+-------------+---------------+\n",
      "|1       |2013-07-25 00:00:00.0|11599        |CLOSED         |\n",
      "|2       |2013-07-25 00:00:00.0|256          |PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00.0|12111        |COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00.0|8827         |CLOSED         |\n",
      "|5       |2013-07-25 00:00:00.0|11318        |COMPLETE       |\n",
      "|6       |2013-07-25 00:00:00.0|7130         |COMPLETE       |\n",
      "|7       |2013-07-25 00:00:00.0|4530         |COMPLETE       |\n",
      "|8       |2013-07-25 00:00:00.0|2911         |PROCESSING     |\n",
      "|9       |2013-07-25 00:00:00.0|5657         |PENDING_PAYMENT|\n",
      "|10      |2013-07-25 00:00:00.0|5648         |PENDING_PAYMENT|\n",
      "+--------+---------------------+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM orders LIMIT 10\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b94ba3f3-61c7-4e38-a191-9823d95132f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   68883|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT count(1) FROM orders\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fd9c1ab3-0b4f-43e2-a405-50c80ffd7927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(create_order_table_partitioned).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d5b3d822-a82c-4c9f-b445-b6e8611cba89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------+\n",
      "|  database|         tableName|isTemporary|\n",
      "+----------+------------------+-----------+\n",
      "|siddhantdb|            orders|      false|\n",
      "|siddhantdb|orders_partitioned|      false|\n",
      "+----------+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW tables\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd87d560-8199-4449-b62f-d6171e9be6cf",
   "metadata": {},
   "source": [
    "### Dynamic partition part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b5f88b73-5d76-453f-add9-5a9cbb123312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|                 key|      value|\n",
      "+--------------------+-----------+\n",
      "|hive.exec.dynamic...|<undefined>|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SET hive.exec.dynamic.partition\").show() #to check the current value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6cee5cd9-b1a0-47d5-9f21-c7c520665262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|                 key|      value|\n",
      "+--------------------+-----------+\n",
      "|hive.exec.dynamic...|<undefined>|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SET hive.exec.dynamic.partition.mode\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "00c78018-bd47-426c-b7cd-f166011893b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: string, value: string]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SET hive.exec.dynamic.partition=true\")\n",
    "spark.sql(\"SET hive.exec.dynamic.partition.mode=nonstrict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0fc7afa7-455c-43b0-8439-1391ca8bbeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                 key|value|\n",
      "+--------------------+-----+\n",
      "|hive.exec.dynamic...| true|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SET hive.exec.dynamic.partition\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "18806167-b527-4e1c-aab3-bd6b6771f3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|                 key|    value|\n",
      "+--------------------+---------+\n",
      "|hive.exec.dynamic...|nonstrict|\n",
      "+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SET hive.exec.dynamic.partition.mode\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5e0f4c3a-5f8c-4044-9022-01bee2e58ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "insert_query= \"\"\" INSERT INTO TABLE orders_partitioned PARTITION (order_month) \n",
    "    SELECT o.*, DATE_FORMAT(order_date, 'yyyy-MM') order_month from orders o\"\"\"\n",
    "\n",
    "spark.sql(insert_query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eb2bbc44-438a-4069-ae40-8963489dcd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+-------------+---------------+-----------+\n",
      "|order_id|order_date           |order_cust_id|order_status   |order_month|\n",
      "+--------+---------------------+-------------+---------------+-----------+\n",
      "|15488   |2013-11-01 00:00:00.0|8987         |PENDING_PAYMENT|2013-11    |\n",
      "|15489   |2013-11-01 00:00:00.0|5359         |PENDING_PAYMENT|2013-11    |\n",
      "|15490   |2013-11-01 00:00:00.0|10149        |COMPLETE       |2013-11    |\n",
      "|15491   |2013-11-01 00:00:00.0|10635        |ON_HOLD        |2013-11    |\n",
      "|15492   |2013-11-01 00:00:00.0|7784         |PENDING_PAYMENT|2013-11    |\n",
      "|15493   |2013-11-01 00:00:00.0|1104         |ON_HOLD        |2013-11    |\n",
      "|15494   |2013-11-01 00:00:00.0|7313         |PROCESSING     |2013-11    |\n",
      "|15495   |2013-11-01 00:00:00.0|7067         |CLOSED         |2013-11    |\n",
      "|15496   |2013-11-01 00:00:00.0|12153        |PENDING_PAYMENT|2013-11    |\n",
      "|15497   |2013-11-01 00:00:00.0|11115        |PENDING_PAYMENT|2013-11    |\n",
      "|15498   |2013-11-01 00:00:00.0|11195        |COMPLETE       |2013-11    |\n",
      "|15499   |2013-11-01 00:00:00.0|7113         |CLOSED         |2013-11    |\n",
      "|15500   |2013-11-01 00:00:00.0|6780         |PENDING_PAYMENT|2013-11    |\n",
      "|15501   |2013-11-01 00:00:00.0|9703         |ON_HOLD        |2013-11    |\n",
      "|15502   |2013-11-01 00:00:00.0|10009        |COMPLETE       |2013-11    |\n",
      "|15503   |2013-11-01 00:00:00.0|6521         |PENDING_PAYMENT|2013-11    |\n",
      "|15504   |2013-11-01 00:00:00.0|10601        |PENDING_PAYMENT|2013-11    |\n",
      "|15505   |2013-11-01 00:00:00.0|1068         |PENDING_PAYMENT|2013-11    |\n",
      "|15506   |2013-11-01 00:00:00.0|2742         |PENDING_PAYMENT|2013-11    |\n",
      "|15507   |2013-11-01 00:00:00.0|3503         |COMPLETE       |2013-11    |\n",
      "+--------+---------------------+-------------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM orders_partitioned LIMIT 20\").show(200, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ce00d192-14f5-492e-9d59-c6012c55bc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   68883|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT count(1) FROM orders_partitioned\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb673c3-fabe-4821-8a96-0a3613f77d2c",
   "metadata": {},
   "source": [
    "# ASSIGNMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5de15d27-f56f-497a-a28a-52146d0774a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../Downloads/Compressed/data-master/nyse_all/nyse_data'\n",
    "database_name = 'nysedb'\n",
    "table_name = 'nyse_eod_part'\n",
    "\n",
    "#partition field: tradeyear of type int \n",
    "#insert using dynamic partition mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ce88e144-5b47-4b0e-894e-732cf3e060ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "| namespace|\n",
      "+----------+\n",
      "|   default|\n",
      "|    nysedb|\n",
      "|siddhantdb|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e12a1b85-7664-43bb-be87-00b5f1e146db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"USE nysedb\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "24419b42-9897-4cd8-b05f-e5baa4e8c729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|current_database()|\n",
      "+------------------+\n",
      "|            nysedb|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT current_database()\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e18bdb9f-447e-433c-a641-6e836fd425e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "|  nysedb| nyse_eod|      false|\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2d11a91f-f841-477a-ab07-7bde226c1231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_nyse_part_table =  f\"\"\" CREATE TABLE IF NOT EXISTS {table_name}(\n",
    "    stockticker STRING,\n",
    "    tradeDate STRING,\n",
    "    openprice FLOAT,\n",
    "    highprice FLOAT,\n",
    "    lowprice FLOAT,\n",
    "    closeprice FLOAT,\n",
    "    volume BIGINT\n",
    ") PARTITIONED BY (tradeyear INT) \n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\n",
    "STORED AS TEXTFILE\n",
    "\"\"\"\n",
    "spark.sql(create_nyse_part_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e618e0ee-76d8-4737-9aac-6a4396572ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+-----------+\n",
      "|database|    tableName|isTemporary|\n",
      "+--------+-------------+-----------+\n",
      "|  nysedb|     nyse_eod|      false|\n",
      "|  nysedb|nyse_eod_part|      false|\n",
      "+--------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0f396c44-912d-47bc-88ef-9bac523d2e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------+---------+--------+----------+------+\n",
      "|stockticker|tradeDate|openprice|highprice|lowprice|closeprice|volume|\n",
      "+-----------+---------+---------+---------+--------+----------+------+\n",
      "|         AA| 19970101|    47.82|    47.82|   47.82|     47.82|     0|\n",
      "|        ABC| 19970101|     6.03|     6.03|    6.03|      6.03|     0|\n",
      "|        ABM| 19970101|     9.25|     9.25|    9.25|      9.25|     0|\n",
      "|        ABT| 19970101|    25.37|    25.37|   25.37|     25.37|     0|\n",
      "|        ABX| 19970101|    28.75|    28.75|   28.75|     28.75|     0|\n",
      "|        ACP| 19970101|     9.12|     9.12|    9.12|      9.12|     0|\n",
      "|        ACV| 19970101|     16.0|     16.0|    16.0|      16.0|     0|\n",
      "|        ADC| 19970101|    21.37|    21.37|   21.37|     21.37|     0|\n",
      "|        ADM| 19970101|    17.24|    17.24|   17.24|     17.24|     0|\n",
      "|        ADX| 19970101|    13.16|    13.16|   13.16|     13.16|     0|\n",
      "+-----------+---------+---------+---------+--------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM nyse_eod LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "879e0417-c7de-4d0a-b760-35acf955b3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------+---------+--------+----------+------+---------+\n",
      "|stockticker|tradeDate|openprice|highprice|lowprice|closeprice|volume|tradeyear|\n",
      "+-----------+---------+---------+---------+--------+----------+------+---------+\n",
      "|         AA| 19970101|    47.82|    47.82|   47.82|     47.82|     0|     1997|\n",
      "|        ABC| 19970101|     6.03|     6.03|    6.03|      6.03|     0|     1997|\n",
      "|        ABM| 19970101|     9.25|     9.25|    9.25|      9.25|     0|     1997|\n",
      "|        ABT| 19970101|    25.37|    25.37|   25.37|     25.37|     0|     1997|\n",
      "|        ABX| 19970101|    28.75|    28.75|   28.75|     28.75|     0|     1997|\n",
      "|        ACP| 19970101|     9.12|     9.12|    9.12|      9.12|     0|     1997|\n",
      "|        ACV| 19970101|     16.0|     16.0|    16.0|      16.0|     0|     1997|\n",
      "|        ADC| 19970101|    21.37|    21.37|   21.37|     21.37|     0|     1997|\n",
      "|        ADM| 19970101|    17.24|    17.24|   17.24|     17.24|     0|     1997|\n",
      "|        ADX| 19970101|    13.16|    13.16|   13.16|     13.16|     0|     1997|\n",
      "+-----------+---------+---------+---------+--------+----------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT n.*, cast(substr(tradeDate, 1, 4) as int) tradeyear FROM nyse_eod n LIMIT 10\").show() #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a0f69825-3616-434f-aeb6-9c9d656ee587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_data_query = \"INSERT INTO TABLE nyse_eod_part PARTITION (tradeyear) SELECT n.*, cast(substr(tradeDate, 1, 4) as int) tradeyear FROM nyse_eod n\"\n",
    "spark.sql(insert_data_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6fdb5d05-c508-4dec-b66e-cd9627f4eae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 9384739|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(1) FROM nyse_eod\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4cacef3d-1c7c-4a16-8130-5fc4319db52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 9384739|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(1) FROM nyse_eod_part\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc99f54f-7cc6-4c1d-ad23-4cc5e0729635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#both have same count and in file manager I checked ... folders are created with names 'tradeyear=1997' up to 'tradeyear=2017'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
