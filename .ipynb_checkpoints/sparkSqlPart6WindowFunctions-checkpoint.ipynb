{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ba3c89-92b8-4f83-a032-a69eedd49fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "os.environ[\"HADOOP_HOME\"] = \"C:\\\\Users\\\\SkJain\\\\Downloads\\\\Compressed\\\\winutils-master\\\\hadoop-3.2.2\"\n",
    "sys.path.append('C:\\\\Users\\\\SkJain\\\\Downloads\\\\Compressed\\\\winutils-master\\\\hadoop-3.2.2\\\\bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9215381f-35bd-4ec9-abe4-160ca6ec25c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config(\"spark.ui.port\", \"0\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName('SparkSql - Window Functions'). \\\n",
    "    master('local'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6970d008-382d-44fc-a0f4-4c7b379fe4f8",
   "metadata": {},
   "source": [
    "## prepare database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39cb6fe9-c43f-4a2f-baa0-10a896cccdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|namespace |\n",
      "+----------+\n",
      "|default   |\n",
      "|nysedb    |\n",
      "|siddhantdb|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASEs\").show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9ef87d9-f518-483d-b8ce-d52790370802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|current_database()|\n",
      "+------------------+\n",
      "|default           |\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT current_database()\").show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d5c2238-757e-45e1-96d1-ecad22afb9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"USE siddhantdb\").show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14051763-e4b2-4205-98db-93a94f9069e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|current_database()|\n",
      "+------------------+\n",
      "|siddhantdb        |\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT current_database()\").show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c9c2eaa-167e-4250-b36f-46902badb993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------+\n",
      "|database  |tableName         |isTemporary|\n",
      "+----------+------------------+-----------+\n",
      "|siddhantdb|orders            |false      |\n",
      "|siddhantdb|orders_partitioned|false      |\n",
      "+----------+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\").show(200, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6045062-17b0-4043-87af-0a594821fa83",
   "metadata": {},
   "source": [
    "### Create employee table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37ed3a98-c0c4-4aaa-b607-e4616d92caf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_employee_query = \"\"\"CREATE TABLE employees (\n",
    "    employee_id     int,\n",
    "    first_name      varchar(20),\n",
    "    last_name       varchar(25),\n",
    "    email           varchar(25),\n",
    "    phone_number    varchar(20),\n",
    "    hire_date       date,\n",
    "    job_id          varchar(10),\n",
    "    salary          decimal(8,2),\n",
    "    commission_pct  decimal(2,2),\n",
    "    manager_id      int,\n",
    "    department_id   int\n",
    "    ) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\t'\"\"\"\n",
    "\n",
    "spark.sql(create_employee_query).show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e04831b3-5183-4e2d-814c-8bdb92045175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------+\n",
      "|database  |tableName         |isTemporary|\n",
      "+----------+------------------+-----------+\n",
      "|siddhantdb|employees         |false      |\n",
      "|siddhantdb|orders            |false      |\n",
      "|siddhantdb|orders_partitioned|false      |\n",
      "+----------+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\").show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e81cefc-ccda-45ce-9ae1-3b0ff8ee4b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_file_path = 'C:/Users/SkJain/Downloads/Compressed/data-master/hr_db/employees'\n",
    "load_data_query = f\"LOAD DATA LOCAL INPATH '{employee_file_path}' INTO TABLE employees\"\n",
    "spark.sql(load_data_query).show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc9fa997-7c16-4175-8281-cde7e89bede5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------+------------+----------+----------+--------+--------------+----------+-------------+\n",
      "|employee_id|first_name|last_name|email   |phone_number|hire_date |job_id    |salary  |commission_pct|manager_id|department_id|\n",
      "+-----------+----------+---------+--------+------------+----------+----------+--------+--------------+----------+-------------+\n",
      "|100        |Steven    |King     |SKING   |515.123.4567|1987-06-17|AD_PRES   |24000.00|null          |null      |90           |\n",
      "|101        |Neena     |Kochhar  |NKOCHHAR|515.123.4568|1989-09-21|AD_VP     |17000.00|null          |100       |90           |\n",
      "|102        |Lex       |De Haan  |LDEHAAN |515.123.4569|1993-01-13|AD_VP     |17000.00|null          |100       |90           |\n",
      "|103        |Alexander |Hunold   |AHUNOLD |590.423.4567|1990-01-03|IT_PROG   |9000.00 |null          |102       |60           |\n",
      "|104        |Bruce     |Ernst    |BERNST  |590.423.4568|1991-05-21|IT_PROG   |6000.00 |null          |103       |60           |\n",
      "|105        |David     |Austin   |DAUSTIN |590.423.4569|1997-06-25|IT_PROG   |4800.00 |null          |103       |60           |\n",
      "|106        |Valli     |Pataballa|VPATABAL|590.423.4560|1998-02-05|IT_PROG   |4800.00 |null          |103       |60           |\n",
      "|107        |Diana     |Lorentz  |DLORENTZ|590.423.5567|1999-02-07|IT_PROG   |4200.00 |null          |103       |60           |\n",
      "|108        |Nancy     |Greenberg|NGREENBE|515.124.4569|1994-08-17|FI_MGR    |12000.00|null          |101       |100          |\n",
      "|109        |Daniel    |Faviet   |DFAVIET |515.124.4169|1994-08-16|FI_ACCOUNT|9000.00 |null          |108       |100          |\n",
      "+-----------+----------+---------+--------+------------+----------+----------+--------+--------------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM employees LIMIT 10\").show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eebbc562-aa57-4643-9c3e-8217573e39ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|107     |\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT count(*) FROM employees\").show(200, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ddb005-339a-4655-b75b-513306688969",
   "metadata": {},
   "source": [
    "### create daily revenue table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c50e0e87-34aa-4337-b966-ef6256bf29ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------+\n",
      "|database  |tableName         |isTemporary|\n",
      "+----------+------------------+-----------+\n",
      "|siddhantdb|employees         |false      |\n",
      "|siddhantdb|orders            |false      |\n",
      "|siddhantdb|orders_partitioned|false      |\n",
      "+----------+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\").show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "07385670-970a-4850-96f2-8814050896cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_order_item_query = \"\"\" CREATE TABLE IF NOT EXISTS order_items (\n",
    "    order_item_id INT,\n",
    "    order_item_order_id INT,\n",
    "    order_item_prod_id INT,\n",
    "    order_item_quantity INT,\n",
    "    order_item_subtotal FLOAT,\n",
    "    order_item_prod_price FLOAT\n",
    "    ) ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(create_order_item_query)\n",
    "orderItemsFilePath = 'datasets/order_items/*'\n",
    "load_data_query = f\"LOAD DATA LOCAL INPATH '{orderItemsFilePath}' INTO TABLE order_items\"\n",
    "spark.sql(load_data_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c76eba4-e0a1-4b4d-903c-2737974b8a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------+\n",
      "|database  |tableName         |isTemporary|\n",
      "+----------+------------------+-----------+\n",
      "|siddhantdb|employees         |false      |\n",
      "|siddhantdb|order_items       |false      |\n",
      "|siddhantdb|orders            |false      |\n",
      "|siddhantdb|orders_partitioned|false      |\n",
      "+----------+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\").show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "232a21d1-9405-40ea-89f9-fbb0afb46840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+------------------+-------------------+-------------------+---------------------+\n",
      "|order_item_id|order_item_order_id|order_item_prod_id|order_item_quantity|order_item_subtotal|order_item_prod_price|\n",
      "+-------------+-------------------+------------------+-------------------+-------------------+---------------------+\n",
      "|1            |1                  |957               |1                  |299.98             |299.98               |\n",
      "|2            |2                  |1073              |1                  |199.99             |199.99               |\n",
      "|3            |2                  |502               |5                  |250.0              |50.0                 |\n",
      "|4            |2                  |403               |1                  |129.99             |129.99               |\n",
      "|5            |4                  |897               |2                  |49.98              |24.99                |\n",
      "|6            |4                  |365               |5                  |299.95             |59.99                |\n",
      "|7            |4                  |502               |3                  |150.0              |50.0                 |\n",
      "|8            |4                  |1014              |4                  |199.92             |49.98                |\n",
      "|9            |5                  |957               |1                  |299.98             |299.98               |\n",
      "|10           |5                  |365               |5                  |299.95             |59.99                |\n",
      "+-------------+-------------------+------------------+-------------------+-------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM order_items LIMIT 10\").show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51628875-26cd-4cd9-9609-ffea88726fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### daily revenue and daily product revenue table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "868034d6-696a-4a88-9f9f-e5bd53552841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_revenue_query = \"\"\"\n",
    "CREATE TABLE daily_revenue\n",
    "AS\n",
    "    SELECT o.order_date,\n",
    "           round(sum(oi.order_item_subtotal), 2) AS revenue\n",
    "    FROM orders o JOIN order_items oi\n",
    "    ON o.order_id = oi.order_item_order_id\n",
    "    WHERE o.order_status IN ('COMPLETE', 'CLOSED')\n",
    "    GROUP BY o.order_date\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(daily_revenue_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a4259b89-f8ba-4137-b92b-159516f2b700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_product_revenue = \"\"\"\n",
    "CREATE TABLE daily_product_revenue\n",
    "    AS\n",
    "    SELECT o.order_date,\n",
    "           oi.order_item_prod_id,\n",
    "           round(sum(oi.order_item_subtotal), 2) AS revenue\n",
    "    FROM orders o JOIN order_items oi\n",
    "    ON o.order_id = oi.order_item_order_id\n",
    "    WHERE o.order_status IN ('COMPLETE', 'CLOSED')\n",
    "    GROUP BY o.order_date, oi.order_item_prod_id\n",
    "\"\"\"\n",
    "spark.sql(daily_product_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "131bac03-fb26-491c-983f-ac0eb8481c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------+-----------+\n",
      "|database  |tableName            |isTemporary|\n",
      "+----------+---------------------+-----------+\n",
      "|siddhantdb|daily_product_revenue|false      |\n",
      "|siddhantdb|daily_revenue        |false      |\n",
      "|siddhantdb|employees            |false      |\n",
      "|siddhantdb|order_items          |false      |\n",
      "|siddhantdb|orders               |false      |\n",
      "|siddhantdb|orders_partitioned   |false      |\n",
      "+----------+---------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\").show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fd75decb-7c76-49b1-8508-ad3fa3b8d737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------+\n",
      "|order_date           |revenue |\n",
      "+---------------------+--------+\n",
      "|2013-08-13 00:00:00.0|17956.88|\n",
      "|2013-10-12 00:00:00.0|35698.85|\n",
      "|2013-11-15 00:00:00.0|34443.22|\n",
      "|2014-03-19 00:00:00.0|32967.69|\n",
      "|2014-04-26 00:00:00.0|53644.32|\n",
      "|2013-09-16 00:00:00.0|29117.35|\n",
      "|2013-09-20 00:00:00.0|29575.36|\n",
      "|2013-12-31 00:00:00.0|52308.99|\n",
      "|2013-09-06 00:00:00.0|61976.1 |\n",
      "|2014-06-15 00:00:00.0|26046.93|\n",
      "+---------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM daily_revenue LIMIT 10\").show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "992ffaf2-e4a2-422e-885d-2df918e6fd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------------+-------+\n",
      "|order_date           |order_item_prod_id|revenue|\n",
      "+---------------------+------------------+-------+\n",
      "|2013-07-27 00:00:00.0|703               |39.98  |\n",
      "|2013-07-29 00:00:00.0|793               |44.97  |\n",
      "|2013-08-12 00:00:00.0|627               |3199.2 |\n",
      "|2013-08-15 00:00:00.0|926               |15.99  |\n",
      "|2013-09-04 00:00:00.0|957               |3599.76|\n",
      "|2013-09-07 00:00:00.0|235               |104.97 |\n",
      "|2013-09-17 00:00:00.0|792               |14.99  |\n",
      "|2013-09-25 00:00:00.0|44                |239.96 |\n",
      "|2013-09-27 00:00:00.0|276               |31.99  |\n",
      "|2013-10-04 00:00:00.0|792               |44.97  |\n",
      "+---------------------+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM daily_product_revenue LIMIT 10\").show(200, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219cfb8a-a36e-4b41-9879-8bc6b281cdac",
   "metadata": {},
   "source": [
    "## Windowing functions overview\n",
    "- Three types:\n",
    "    - Aggregate Functions (sum, min, max, avg)\n",
    "    - Window Functions (lead, lag, first_value, last_value)\n",
    "    - Ranking Functions (rank, dense_rank, row_number etc.)\n",
    "- for all aggregations we use OVER clause\n",
    "- with aggregate functions we typically use PARTITION BY\n",
    "- with ranking and windowing functions we might use ORDER BY or a combination of both PARTITION BY and ORDER BY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "511d2556-aaed-4bd2-9a14-14bee5741319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+--------+\n",
      "|employee_id|department_id|salary  |\n",
      "+-----------+-------------+--------+\n",
      "|100        |90           |24000.00|\n",
      "|101        |90           |17000.00|\n",
      "|102        |90           |17000.00|\n",
      "|103        |60           |9000.00 |\n",
      "|104        |60           |6000.00 |\n",
      "|105        |60           |4800.00 |\n",
      "|106        |60           |4800.00 |\n",
      "|107        |60           |4200.00 |\n",
      "|108        |100          |12000.00|\n",
      "|109        |100          |9000.00 |\n",
      "+-----------+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT employee_id, department_id, salary from employees LIMIT 10\").show(200, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ade7f3-4565-421f-b1e8-20feb8cfff62",
   "metadata": {},
   "source": [
    "### Windowing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "029c140e-2711-4477-8559-499fd20eb7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+--------+-----------------+----------+-----------+----------+------------+\n",
      "|employee_id|department_id|salary  |employees_in_dept|salaryRank|lead_emp_id|lag_emp_id|lead_emp_sal|\n",
      "+-----------+-------------+--------+-----------------+----------+-----------+----------+------------+\n",
      "|178        |null         |7000.00 |1                |45        |null       |null      |null        |\n",
      "|200        |10           |4400.00 |1                |61        |null       |null      |null        |\n",
      "|201        |20           |13000.00|2                |6         |202        |null      |6000.00     |\n",
      "|202        |20           |6000.00 |2                |56        |null       |201       |null        |\n",
      "|114        |30           |11000.00|6                |11        |115        |null      |3100.00     |\n",
      "|115        |30           |3100.00 |6                |78        |116        |114       |2900.00     |\n",
      "|116        |30           |2900.00 |6                |84        |117        |115       |2800.00     |\n",
      "|117        |30           |2800.00 |6                |87        |118        |116       |2600.00     |\n",
      "|118        |30           |2600.00 |6                |93        |119        |117       |2500.00     |\n",
      "|119        |30           |2500.00 |6                |97        |null       |118       |null        |\n",
      "+-----------+-------------+--------+-----------------+----------+-----------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT employee_id, department_id, salary,\n",
    "count(1) OVER(PARTITION BY  department_id) as employees_in_dept,\n",
    "rank() OVER(ORDER BY salary DESC) as salaryRank,\n",
    "lead(employee_id) OVER(PARTITION BY department_id ORDER BY salary DESC) as lead_emp_id,\n",
    "lag(employee_id) OVER(PARTITION BY department_id ORDER BY salary DESC) as lag_emp_id,\n",
    "lead(salary) OVER(PARTITION BY department_id ORDER BY salary DESC) as lead_emp_sal\n",
    "from employees LIMIT 10\"\"\").show(200, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab4c834-89c2-468b-9228-4f87accf6b8c",
   "metadata": {},
   "source": [
    "### aggregate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75ec78b8-cddb-430b-8710-8817573dff31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+--------+\n",
      "|employee_id|department_id|salary  |\n",
      "+-----------+-------------+--------+\n",
      "|178        |null         |7000.00 |\n",
      "|200        |10           |4400.00 |\n",
      "|202        |20           |6000.00 |\n",
      "|201        |20           |13000.00|\n",
      "|119        |30           |2500.00 |\n",
      "|118        |30           |2600.00 |\n",
      "|117        |30           |2800.00 |\n",
      "|116        |30           |2900.00 |\n",
      "|115        |30           |3100.00 |\n",
      "|114        |30           |11000.00|\n",
      "+-----------+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT employee_id, department_id, salary from employees ORDER BY department_id, salary  LIMIT 10\").show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "628edd97-290b-46ac-8b56-7304ae52b975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+\n",
      "|department_id|sum(salary)|\n",
      "+-------------+-----------+\n",
      "|null         |7000.00    |\n",
      "|10           |4400.00    |\n",
      "|20           |19000.00   |\n",
      "|30           |24900.00   |\n",
      "|40           |6500.00    |\n",
      "|50           |156400.00  |\n",
      "|60           |28800.00   |\n",
      "|70           |10000.00   |\n",
      "|80           |304500.00  |\n",
      "|90           |58000.00   |\n",
      "+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# total salary per department\n",
    "spark.sql(\"SELECT department_id, sum(salary) from employees GROUP BY department_id ORDER BY department_id LIMIT 10\").show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "081b74f1-ac3f-4e33-8ca1-6f6e7419c746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-------------+\n",
      "|department_id|employee_id|SalPercentage|\n",
      "+-------------+-----------+-------------+\n",
      "|null         |178        |null         |\n",
      "|10           |200        |100.00       |\n",
      "|20           |201        |68.42        |\n",
      "|20           |202        |31.58        |\n",
      "|30           |114        |44.18        |\n",
      "|30           |115        |12.45        |\n",
      "|30           |116        |11.65        |\n",
      "|30           |117        |11.24        |\n",
      "|30           |118        |10.44        |\n",
      "|30           |119        |10.04        |\n",
      "+-------------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#GET PERCENTAGE SALARY BY DEPARTMENT WITHOUT WINDOW FUNCTIONS\n",
    "query = \"\"\" \n",
    "SELECT e1.department_id, e1.employee_id, round((salary/totalSalary)*100,2) as SalPercentage\n",
    "from employees e1\n",
    "LEFT OUTER JOIN \n",
    "(SELECT department_id, sum(salary) as totalSalary from employees GROUP BY department_id) e2\n",
    "ON e1.department_id=e2.department_id\n",
    "ORDER BY e1.department_id\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e601240f-60a1-4002-96e9-806ee34cc450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-------------+-----------+-----------+-----------+-----------+\n",
      "|department_id|employee_id|SalPercentage|dep_avg_sal|dep_min_sal|dep_max_sal|dep_cnt_sal|\n",
      "+-------------+-----------+-------------+-----------+-----------+-----------+-----------+\n",
      "|null         |178        |100.00       |7000.000000|7000.00    |7000.00    |1          |\n",
      "|10           |200        |100.00       |4400.000000|4400.00    |4400.00    |1          |\n",
      "|20           |202        |31.58        |9500.000000|6000.00    |13000.00   |2          |\n",
      "|20           |201        |68.42        |9500.000000|6000.00    |13000.00   |2          |\n",
      "|30           |114        |44.18        |4150.000000|2500.00    |11000.00   |6          |\n",
      "|30           |115        |12.45        |4150.000000|2500.00    |11000.00   |6          |\n",
      "|30           |116        |11.65        |4150.000000|2500.00    |11000.00   |6          |\n",
      "|30           |117        |11.24        |4150.000000|2500.00    |11000.00   |6          |\n",
      "|30           |118        |10.44        |4150.000000|2500.00    |11000.00   |6          |\n",
      "|30           |119        |10.04        |4150.000000|2500.00    |11000.00   |6          |\n",
      "+-------------+-----------+-------------+-----------+-----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT department_id, employee_id,\n",
    "round((salary / sum(salary) OVER(PARTITION BY department_id))*100,2) SalPercentage,\n",
    "avg(salary) OVER(PARTITION BY department_id) dep_avg_sal,\n",
    "min(salary) OVER(PARTITION BY department_id) dep_min_sal,\n",
    "max(salary) OVER(PARTITION BY department_id) dep_max_sal,\n",
    "count(salary) OVER(PARTITION BY department_id) dep_cnt_sal\n",
    "FROM employees \n",
    "ORDER BY department_id\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).show(200, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236c6d63-a5fe-4918-ad61-88987f41afd9",
   "metadata": {},
   "source": [
    "### LEAD and LAG functions\n",
    "- to get prior or following record respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1c0473a0-6e8e-4ba4-a513-0f4f5edb2dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------+---------------------+-------------+\n",
      "|order_date           |revenue |prior_date           |prior_revenue|\n",
      "+---------------------+--------+---------------------+-------------+\n",
      "|2014-07-24 00:00:00.0|50885.19|2014-07-23 00:00:00.0|38795.23     |\n",
      "|2014-07-23 00:00:00.0|38795.23|2014-07-22 00:00:00.0|36717.24     |\n",
      "|2014-07-22 00:00:00.0|36717.24|2014-07-21 00:00:00.0|51427.7      |\n",
      "|2014-07-21 00:00:00.0|51427.7 |2014-07-20 00:00:00.0|60047.45     |\n",
      "|2014-07-20 00:00:00.0|60047.45|2014-07-19 00:00:00.0|38420.99     |\n",
      "|2014-07-19 00:00:00.0|38420.99|2014-07-18 00:00:00.0|43856.6      |\n",
      "|2014-07-18 00:00:00.0|43856.6 |2014-07-17 00:00:00.0|36384.77     |\n",
      "|2014-07-17 00:00:00.0|36384.77|2014-07-16 00:00:00.0|43011.92     |\n",
      "|2014-07-16 00:00:00.0|43011.92|2014-07-15 00:00:00.0|53480.23     |\n",
      "|2014-07-15 00:00:00.0|53480.23|2014-07-14 00:00:00.0|29937.52     |\n",
      "+---------------------+--------+---------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"select dr.*,\n",
    "lead(order_date) OVER(ORDER BY order_date desc) AS prior_date,\n",
    "lead(revenue) OVER(ORDER BY order_date desc) AS prior_revenue\n",
    "from daily_revenue as dr\n",
    "order by order_date desc\n",
    "limit 10 \"\"\"\n",
    "\n",
    "spark.sql(query).show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "05380f3c-dec6-4da3-8676-e63bd905bca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------+---------------------+-------------+\n",
      "|order_date           |revenue |prior_date           |prior_revenue|\n",
      "+---------------------+--------+---------------------+-------------+\n",
      "|2013-07-25 00:00:00.0|31547.23|null                 |null         |\n",
      "|2013-07-26 00:00:00.0|54713.23|2013-07-25 00:00:00.0|31547.23     |\n",
      "|2013-07-27 00:00:00.0|48411.48|2013-07-26 00:00:00.0|54713.23     |\n",
      "|2013-07-28 00:00:00.0|35672.03|2013-07-27 00:00:00.0|48411.48     |\n",
      "|2013-07-29 00:00:00.0|54579.7 |2013-07-28 00:00:00.0|35672.03     |\n",
      "|2013-07-30 00:00:00.0|49329.29|2013-07-29 00:00:00.0|54579.7      |\n",
      "|2013-07-31 00:00:00.0|59212.49|2013-07-30 00:00:00.0|49329.29     |\n",
      "|2013-08-01 00:00:00.0|49160.08|2013-07-31 00:00:00.0|59212.49     |\n",
      "|2013-08-02 00:00:00.0|50688.58|2013-08-01 00:00:00.0|49160.08     |\n",
      "|2013-08-03 00:00:00.0|43416.74|2013-08-02 00:00:00.0|50688.58     |\n",
      "+---------------------+--------+---------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#last value will be null in case of lead and first value for lag \n",
    "#by default it leads ore lag 1 position (1 record next or 1 record prev)\n",
    "# since here in over we have ordered in desc that means first date will have null value\n",
    "\n",
    "query = \"\"\"select dr.*,\n",
    "lead(order_date) OVER(ORDER BY order_date desc) AS prior_date,\n",
    "lead(revenue) OVER(ORDER BY order_date desc) AS prior_revenue\n",
    "from daily_revenue as dr\n",
    "order by order_date\n",
    "limit 10 \"\"\"\n",
    "\n",
    "spark.sql(query).show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2460e6fb-b9cc-4a8d-8b1d-e9bec3e43af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------+---------------------+-------------+\n",
      "|order_date           |revenue |prior_date           |prior_revenue|\n",
      "+---------------------+--------+---------------------+-------------+\n",
      "|2013-07-25 00:00:00.0|31547.23|null                 |null         |\n",
      "|2013-07-26 00:00:00.0|54713.23|null                 |null         |\n",
      "|2013-07-27 00:00:00.0|48411.48|null                 |null         |\n",
      "|2013-07-28 00:00:00.0|35672.03|null                 |null         |\n",
      "|2013-07-29 00:00:00.0|54579.7 |null                 |null         |\n",
      "|2013-07-30 00:00:00.0|49329.29|null                 |null         |\n",
      "|2013-07-31 00:00:00.0|59212.49|null                 |null         |\n",
      "|2013-08-01 00:00:00.0|49160.08|2013-07-25 00:00:00.0|31547.23     |\n",
      "|2013-08-02 00:00:00.0|50688.58|2013-07-26 00:00:00.0|54713.23     |\n",
      "|2013-08-03 00:00:00.0|43416.74|2013-07-27 00:00:00.0|48411.48     |\n",
      "+---------------------+--------+---------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lead or lag by sevaral steps\n",
    "\n",
    "query = \"\"\"select dr.*,\n",
    "lead(order_date, 7) OVER(ORDER BY order_date desc) AS prior_date,\n",
    "lead(revenue, 7) OVER(ORDER BY order_date desc) AS prior_revenue\n",
    "from daily_revenue as dr\n",
    "order by order_date\n",
    "limit 10 \"\"\"\n",
    "\n",
    "spark.sql(query).show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9dde5021-1aa3-433e-850a-17bf67e75c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------+---------------------+-------------+\n",
      "|order_date           |revenue |prior_date           |prior_revenue|\n",
      "+---------------------+--------+---------------------+-------------+\n",
      "|2013-07-25 00:00:00.0|31547.23|NA                   |0.0          |\n",
      "|2013-07-26 00:00:00.0|54713.23|NA                   |0.0          |\n",
      "|2013-07-27 00:00:00.0|48411.48|NA                   |0.0          |\n",
      "|2013-07-28 00:00:00.0|35672.03|NA                   |0.0          |\n",
      "|2013-07-29 00:00:00.0|54579.7 |NA                   |0.0          |\n",
      "|2013-07-30 00:00:00.0|49329.29|NA                   |0.0          |\n",
      "|2013-07-31 00:00:00.0|59212.49|NA                   |0.0          |\n",
      "|2013-08-01 00:00:00.0|49160.08|2013-07-25 00:00:00.0|31547.23     |\n",
      "|2013-08-02 00:00:00.0|50688.58|2013-07-26 00:00:00.0|54713.23     |\n",
      "|2013-08-03 00:00:00.0|43416.74|2013-07-27 00:00:00.0|48411.48     |\n",
      "+---------------------+--------+---------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# replace the null values which we get at start or end with something else (pass as third arg)\n",
    "\n",
    "query = \"\"\"select dr.*,\n",
    "lead(order_date, 7, 'NA') OVER(ORDER BY order_date desc) AS prior_date,\n",
    "lead(revenue, 7, 0) OVER(ORDER BY order_date desc) AS prior_revenue\n",
    "from daily_revenue as dr\n",
    "order by order_date\n",
    "limit 10 \"\"\"\n",
    "\n",
    "spark.sql(query).show(200, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d0ec64-2334-42fb-845d-33816b2759f4",
   "metadata": {},
   "source": [
    "### use lead lag with partition by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "719743eb-4490-4001-9422-17bfad05c713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------------+-------+------------+------------+\n",
      "|order_date           |order_item_prod_id|revenue|next_prod_id|next_revenue|\n",
      "+---------------------+------------------+-------+------------+------------+\n",
      "|2013-07-25 00:00:00.0|1004              |5599.72|191         |5099.49     |\n",
      "|2013-07-25 00:00:00.0|191               |5099.49|957         |4499.7      |\n",
      "|2013-07-25 00:00:00.0|957               |4499.7 |365         |3359.44     |\n",
      "|2013-07-25 00:00:00.0|365               |3359.44|1073        |2999.85     |\n",
      "|2013-07-25 00:00:00.0|1073              |2999.85|1014        |2798.88     |\n",
      "|2013-07-25 00:00:00.0|1014              |2798.88|403         |1949.85     |\n",
      "|2013-07-25 00:00:00.0|403               |1949.85|502         |1650.0      |\n",
      "|2013-07-25 00:00:00.0|502               |1650.0 |627         |1079.73     |\n",
      "|2013-07-25 00:00:00.0|627               |1079.73|226         |599.99      |\n",
      "|2013-07-25 00:00:00.0|226               |599.99 |24          |319.96      |\n",
      "+---------------------+------------------+-------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"select dr.*,\n",
    "lead(order_item_prod_id) OVER(PARTITION BY order_date ORDER BY revenue desc) AS next_prod_id,\n",
    "lead(revenue) OVER(PARTITION BY order_date ORDER BY revenue desc) AS next_revenue\n",
    "from daily_product_revenue as dr\n",
    "order by order_date, revenue desc\n",
    "limit 10 \"\"\"\n",
    "\n",
    "spark.sql(query).show(200, False)\n",
    "\n",
    "#last value in each partion will be null\n",
    "#can be resolved the same way as we did on top, by passing 3 args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde6856f-bf26-4d28-8a14-7df1940c2a24",
   "metadata": {},
   "source": [
    "### getting first and last values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aad635ab-4853-4ef7-b9ac-a5e9d7e9bb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------------+--------+-------------+-------------+\n",
      "|order_date           |order_item_prod_id|revenue |first_prod_id|first_revenue|\n",
      "+---------------------+------------------+--------+-------------+-------------+\n",
      "|2013-07-25 00:00:00.0|1004              |5599.72 |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|191               |5099.49 |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|957               |4499.7  |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|365               |3359.44 |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|1073              |2999.85 |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|1014              |2798.88 |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|403               |1949.85 |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|502               |1650.0  |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|627               |1079.73 |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|226               |599.99  |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|24                |319.96  |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|821               |207.96  |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|625               |199.99  |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|705               |119.99  |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|572               |119.97  |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|666               |109.99  |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|725               |108.0   |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|134               |100.0   |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|906               |99.96   |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|828               |95.97   |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|810               |79.96   |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|924               |79.95   |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|926               |79.95   |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|93                |74.97   |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|835               |63.98   |1004         |5599.72      |\n",
      "|2013-07-25 00:00:00.0|897               |49.98   |1004         |5599.72      |\n",
      "|2013-07-26 00:00:00.0|1004              |10799.46|1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|365               |7978.67 |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|957               |6899.54 |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|191               |6799.32 |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|1014              |4798.08 |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|502               |4250.0  |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|1073              |3999.8  |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|403               |3249.75 |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|627               |3039.24 |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|691               |399.95  |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|818               |287.94  |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|565               |280.0   |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|278               |269.94  |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|822               |239.95  |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|282               |159.95  |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|804               |159.92  |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|917               |153.93  |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|982               |149.99  |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|116               |134.97  |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|828               |127.96  |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|135               |110.0   |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|134               |100.0   |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|564               |90.0    |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|792               |89.94   |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|897               |74.97   |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|775               |39.96   |1004         |10799.46     |\n",
      "|2013-07-26 00:00:00.0|172               |30.0    |1004         |10799.46     |\n",
      "|2013-07-27 00:00:00.0|1004              |9599.52 |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|191               |5999.4  |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|957               |5699.62 |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|1073              |5399.73 |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|365               |5099.15 |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|502               |5050.0  |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|1014              |4498.2  |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|403               |2469.81 |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|627               |2039.49 |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|203               |399.99  |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|728               |390.0   |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|828               |223.93  |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|771               |199.95  |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|172               |150.0   |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|647               |134.99  |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|715               |129.99  |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|567               |125.0   |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|93                |124.95  |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|135               |110.0   |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|924               |95.94   |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|886               |74.97   |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|797               |71.96   |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|564               |60.0    |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|821               |51.99   |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|906               |49.98   |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|893               |49.98   |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|792               |44.97   |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|703               |39.98   |1004         |9599.52      |\n",
      "|2013-07-27 00:00:00.0|273               |27.99   |1004         |9599.52      |\n",
      "|2013-07-28 00:00:00.0|1004              |5599.72 |1004         |5599.72      |\n",
      "|2013-07-28 00:00:00.0|957               |5099.66 |1004         |5599.72      |\n",
      "|2013-07-28 00:00:00.0|365               |4799.2  |1004         |5599.72      |\n",
      "|2013-07-28 00:00:00.0|403               |4419.66 |1004         |5599.72      |\n",
      "|2013-07-28 00:00:00.0|191               |4299.57 |1004         |5599.72      |\n",
      "|2013-07-28 00:00:00.0|502               |3650.0  |1004         |5599.72      |\n",
      "|2013-07-28 00:00:00.0|1014              |2748.9  |1004         |5599.72      |\n",
      "|2013-07-28 00:00:00.0|1073              |2399.88 |1004         |5599.72      |\n",
      "|2013-07-28 00:00:00.0|627               |1119.72 |1004         |5599.72      |\n",
      "|2013-07-28 00:00:00.0|564               |300.0   |1004         |5599.72      |\n",
      "|2013-07-28 00:00:00.0|858               |199.99  |1004         |5599.72      |\n",
      "|2013-07-28 00:00:00.0|728               |195.0   |1004         |5599.72      |\n",
      "|2013-07-28 00:00:00.0|273               |139.95  |1004         |5599.72      |\n",
      "|2013-07-28 00:00:00.0|567               |125.0   |1004         |5599.72      |\n",
      "|2013-07-28 00:00:00.0|249               |109.94  |1004         |5599.72      |\n",
      "|2013-07-28 00:00:00.0|917               |87.96   |1004         |5599.72      |\n",
      "|2013-07-28 00:00:00.0|235               |69.98   |1004         |5599.72      |\n",
      "|2013-07-28 00:00:00.0|835               |63.98   |1004         |5599.72      |\n",
      "+---------------------+------------------+--------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"select dr.*,\n",
    "first_value(order_item_prod_id) OVER(PARTITION BY order_date ORDER BY revenue desc) AS first_prod_id,\n",
    "first_value(revenue) OVER(PARTITION BY order_date ORDER BY revenue desc) AS first_revenue\n",
    "from daily_product_revenue as dr\n",
    "order by order_date, revenue desc\n",
    "limit 100 \"\"\"\n",
    "\n",
    "spark.sql(query).show(200, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca765b37-2f81-499c-bcf1-941c1ed28ef1",
   "metadata": {},
   "source": [
    "#### last_value is little different\n",
    "- with query we need to mention 'ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING'\n",
    "- because by defautt it uses 'ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW'\n",
    "- other it will return the record itself\n",
    "- since at the time this record is accessed it is the last record"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
